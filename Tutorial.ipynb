{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphology (Tutorial 3)\n",
    "***\n",
    "# Table of Contents\n",
    "1.   [Setup](#Setup)\n",
    "2.   [Exercise 1 - Connected Components](#Exercise-1---Connected-Components)\n",
    "3.   [Exercise 2 - Dilation](#Exercise-2---Dilation)\n",
    "4.   [Exercise 3 - Erosion](#Exercise-3---Erosion)\n",
    "5.   [Exercise 4 - Opening](#Exercise-4---Opening)\n",
    "6.   [Exercise 5 - Closing](#Exercise-5---Closing)\n",
    "7.   [Exercise 6 - Line Segmentation](#Exercise-6---Line-Segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "These libraries are needed for this project:\n",
    "* opencv (cv2) - For image processing\n",
    "* numpy - For its arrays\n",
    "* matplotlib - Plotting histograms\n",
    "* os - File traversal\n",
    "* tqdm.notebook - tqdm progress bars, but for ipynb files\n",
    "* Classes - Custom classes written by me for this assignment\n",
    "\n",
    "I am using python 3.8 and will be providing an html file generated by jubyter notebooks because I think its more\n",
    "presentable than just the ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "# Load the images into memory\n",
    "shapes = cv2.imread('Images/shapes.jpg')\n",
    "euro = cv2.imread('Images/Euro_Coins.jpg')\n",
    "text = cv2.imread('Images/text.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Connected Components\n",
    "\n",
    "### getObjects\n",
    "\n",
    "For this exercise I wrote the getObjects function. In the function I first apply a grayscale filter to the input image,\n",
    "followed by a gaussian blur. This blur smoothens the objects edges making it easier to get them labelled.\n",
    "\n",
    "The next step is to get the object labels using the connectedComponents function. Then I colour the components to\n",
    "differentiate between the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getObjects(image, title):\n",
    "    # gray scale\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # blur using gaussian to help reduce noise\n",
    "    dst = cv2.GaussianBlur(gray,(13,13),cv2.BORDER_DEFAULT)\n",
    "    # treshold image\n",
    "    ret, thresh = cv2.threshold(dst,230,255,cv2.THRESH_BINARY_INV)\n",
    "    # save treshold\n",
    "    cv2.imwrite(\"Output/threshold \"+title+\".png\", thresh, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "    # get labels\n",
    "    ret, labels = cv2.connectedComponents(thresh)\n",
    "\n",
    "    # Colour the labels\n",
    "    label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "    blank_ch = 255 * np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    # save labels as image\n",
    "    cv2.imwrite(\"Output/\"+title+str(ret-1)+\".png\", labeled_img, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "getObjects(shapes.copy(), \"shapes\")\n",
    "getObjects(euro.copy(), \"euro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here I can see that the white mask of the objects came out very clean with no noise inside the objects. This in turn\n",
    "gave a clean input to connectedComponents which labeled each object perfectly.\n",
    "\n",
    "Input | Threshold | Labeled\n",
    "-|-|-\n",
    "<img src=\"Images/Euro_Coins.jpg\"> | <img src=\"Output/threshold euro.png\"> | <img src=\"Output/euro8.png\">\n",
    "<img src=\"Images/shapes.jpg\"> | <img src=\"Output/threshold shapes.png\"> | <img src=\"Output/shapes6.png\">\n",
    "\n",
    "\n",
    "### getROI\n",
    "With getROI I am able to get a ROI of each object in the image. Similar to getObjects, the input image goes through a\n",
    "grayscale, gaussian and threshold filter. Then by using the findContours function I am able to get split the input image\n",
    "into various ROIs by creating a bounding box with each contour's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getROI(image, title):\n",
    "    # gray scale\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # blur using gaussian to help reduce noise\n",
    "    dst = cv2.GaussianBlur(gray,(13,13),cv2.BORDER_DEFAULT)\n",
    "    # treshold image\n",
    "    ret, thresh = cv2.threshold(dst,230,255,cv2.THRESH_BINARY_INV)\n",
    "    # getting ROIs with findContours\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    i = 1\n",
    "    for cnt in contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(cnt)\n",
    "        ROI = image[y:y+h,x:x+w]\n",
    "        cv2.imwrite(\"Output/\"+title+\" object \"+str(i)+\".png\", ROI, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "        i+=1\n",
    "\n",
    "getROI(shapes.copy(), \"shapes\")\n",
    "getROI(euro.copy(), \"euro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The getRoi function is able to pick each object out.\n",
    "\n",
    "When passed the shapes.jpg, we get these 6 ROIs, each showing a shape:\n",
    "\n",
    "<img src=\"Output/shapes object 1.png\">\n",
    "<img src=\"Output/shapes object 2.png\">\n",
    "<img src=\"Output/shapes object 3.png\">\n",
    "<img src=\"Output/shapes object 4.png\">\n",
    "<img src=\"Output/shapes object 5.png\">\n",
    "<img src=\"Output/shapes object 6.png\">\n",
    "\n",
    "And when passed the Euro_Coins.jpg, we get these 8 ROIs, each showing a coin:\n",
    "\n",
    "<img src=\"Output/euro object 1.png\">\n",
    "<img src=\"Output/euro object 2.png\">\n",
    "<img src=\"Output/euro object 3.png\">\n",
    "<img src=\"Output/euro object 4.png\">\n",
    "<img src=\"Output/euro object 5.png\">\n",
    "<img src=\"Output/euro object 6.png\">\n",
    "<img src=\"Output/euro object 7.png\">\n",
    "<img src=\"Output/euro object 8.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Dilation\n",
    "\n",
    "For this exercise I dilate the text.png image using two different kernels too see their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "dilate = cv2.dilate(text.copy(), kernel)\n",
    "cv2.imwrite(\"Output/dilated text 3x3.png\", dilate, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "kernel = np.ones((5, 5), 'uint8')\n",
    "dilate = cv2.dilate(text.copy(), kernel)\n",
    "cv2.imwrite(\"Output/dilated text 5x5.png\", dilate, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input | 3x3 | 5x5\n",
    "-|-|-\n",
    "<img src=\"Images/text.png\"> | <img src=\"Output/dilated text 3x3.png\"> | <img src=\"Output/dilated text 5x5.png\">\n",
    "\n",
    "As the kernel increases the dilate effect is increased as it impacts a larger area. With the 5x5 kernel, the text is no\n",
    "longer readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Erosion\n",
    "\n",
    "For this exercise I erode the text.png image using two different kernels too see their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "erode = cv2.erode(text.copy(), kernel)\n",
    "cv2.imwrite(\"Output/eroded text 3x3.png\", erode, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "kernel = np.ones((5, 5), 'uint8')\n",
    "erode = cv2.erode(text.copy(), kernel)\n",
    "cv2.imwrite(\"Output/eroded text 5x5.png\", erode, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input | 3x3 | 5x5\n",
    "-|-|-\n",
    "<img src=\"Images/text.png\"> | <img src=\"Output/eroded text 3x3.png\"> | <img src=\"Output/eroded text 5x5.png\">\n",
    "\n",
    "As the kernel increases the erode effect is increased as it impacts a larger area. Both kernels bolded the text however\n",
    "with the 5x5 kernel this effect is almost too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 - Opening\n",
    "\n",
    "For this exercise I open the text.png image using two different kernels too see their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "open = cv2.morphologyEx(text.copy(), cv2.MORPH_OPEN ,kernel)\n",
    "cv2.imwrite(\"Output/open text 3x3.png\", open, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "kernel = np.ones((5, 5), 'uint8')\n",
    "open = cv2.morphologyEx(text.copy(), cv2.MORPH_OPEN ,kernel)\n",
    "cv2.imwrite(\"Output/open text 5x5.png\", open, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input | 3x3 | 5x5\n",
    "-|-|-\n",
    "<img src=\"Images/text.png\"> | <img src=\"Output/open text 3x3.png\"> | <img src=\"Output/open text 5x5.png\">\n",
    "\n",
    "I saw that using opening barely affected the text as with both kernels the text is still very readable. However I noticed\n",
    "that the letters became a bit smudged, and I think this would be useful to create a mask of the letter objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 - Closing\n",
    "\n",
    "For this exercise I close the text.png image using two different kernels too see their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "close = cv2.morphologyEx(text.copy(), cv2.MORPH_CLOSE ,kernel)\n",
    "cv2.imwrite(\"Output/close text 3x3.png\", close, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "kernel = np.ones((5, 5), 'uint8')\n",
    "close = cv2.morphologyEx(text.copy(), cv2.MORPH_CLOSE ,kernel)\n",
    "cv2.imwrite(\"Output/close text 5x5.png\", close, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input | 3x3 | 5x5\n",
    "-|-|-\n",
    "<img src=\"Images/text.png\"> | <img src=\"Output/close text 3x3.png\"> | <img src=\"Output/close text 5x5.png\">\n",
    "\n",
    "Input | 3x3 | 5x5\n",
    "-|-|-\n",
    "<img src=\"Images/text.png\"> | <img src=\"Output/open text 3x3.png\"> | <img src=\"Output/open text 5x5.png\">\n",
    "\n",
    "I saw that this kernel's output was similar to the dilate output. However as is explained in the notes the erode step\n",
    "that is done after the dilate step as the barely visible letters get back some of their colour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 - Line Segmentation\n",
    "\n",
    "For this exercise I decided to not use histograms because I felt that for this case, I did not need to use them. Having\n",
    "now learnt the application of the above techniques I recognised that by applying a pseudo close I would be able to\n",
    "extract 4 rectangles that cover the words in the text. I say pseudo since the dilation and erosion applied will have\n",
    "different kernels passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Get the grayscale\n",
    "gray = cv2.cvtColor(text.copy(),cv2.COLOR_BGR2GRAY)\n",
    "# Apply the gaussian filter because of the noise\n",
    "dst = cv2.GaussianBlur(gray, (13,13), cv2.BORDER_DEFAULT)\n",
    "# Apply a high threshold\n",
    "ret, thresh = cv2.threshold(dst, 187, 255, cv2.THRESH_BINARY)\n",
    "# Dilate with a wide kernel\n",
    "kernel = np.ones((5, 70), 'uint8')\n",
    "dilate = cv2.morphologyEx(thresh, cv2.MORPH_DILATE ,kernel)\n",
    "# Now apply erosion with a very wide kernel, and as high as it can get before making lines meet\n",
    "kernel = np.ones((25, 130), 'uint8')\n",
    "erode = cv2.morphologyEx(dilate, cv2.MORPH_ERODE ,kernel)\n",
    "# Flip white and black\n",
    "final = cv2.bitwise_not(erode)\n",
    "cv2.imwrite(\"Output/LineThresh.png\", final, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Input | Line Mask \n",
    "-|-\n",
    "<img src=\"Images/text.png\"> | <img src=\"Output/LineThresh.png\"> \n",
    "\n",
    "\n",
    "Now that I have successfully approximated where the lines are, I will use the connectedComponents function and the\n",
    "colouring done previously to create a colour mask of these 4 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# get labels\n",
    "ret, labels = cv2.connectedComponents(final)\n",
    "\n",
    "# Colour the labels\n",
    "label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "blank_ch = 255 * np.ones_like(label_hue)\n",
    "labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "labeled_img[label_hue == 0] = 0\n",
    "# save labels as image\n",
    "cv2.imwrite(\"Output/LabelledLines.png\", labeled_img, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input | Labeled Line Mask \n",
    "-|-\n",
    "<img src=\"Images/text.png\"> | <img src=\"Output/LabelledLines.png\"> \n",
    "\n",
    "Now that each line is very clearly distinguishable I will use the coloured mask to paint over the text with their new\n",
    "colours.\n",
    "\n",
    "I will achieve this by following these steps:\n",
    "\n",
    "* Apply a 3x3 kernel closure on the image\n",
    "    * This step is done to remove a bunch of noise from the grayed out text image that would otherwise be enhanced by\n",
    "        the next step.\n",
    "* Do the reverse of a gaussian filter and sharpen the image\n",
    "* Erode the image with a 3x3 kernel\n",
    "* Apply a 0 threshold\n",
    "* Flip black and white\n",
    "\n",
    "This will result with a white mask of the letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gray = cv2.cvtColor(text.copy(),cv2.COLOR_BGR2GRAY)\n",
    "kernel = np.ones((5, 5), 'uint8')\n",
    "close = cv2.morphologyEx(gray, cv2.MORPH_CLOSE ,kernel)\n",
    "kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "im = cv2.filter2D(close, -1, kernel)\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "erode = cv2.morphologyEx(im, cv2.MORPH_ERODE ,kernel)\n",
    "ret, thresh = cv2.threshold(erode, 0, 235, cv2.THRESH_BINARY)\n",
    "txt_white = cv2.bitwise_not(thresh)\n",
    "cv2.imwrite(\"Output/TextLettersMask.png\", thresh, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input | Letter Mask \n",
    "-|-\n",
    "<img src=\"Images/text.png\"> | <img src=\"Output/TextLettersMask.png\"> \n",
    "\n",
    "Now the only thing that is left is to go over the labeled image (the one with the coloured lines). In the loop I use the\n",
    "enumerate function which allows me to check the txt_white image (the one shown above). When the checked pixel is changed\n",
    "to that of the labelled image. This results in the text getting a bit bold and getting some new colour, where the above\n",
    "code identified a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "c_text = text.copy()\n",
    "for i, y in enumerate(labeled_img):\n",
    "    for j, x in enumerate(y):\n",
    "        if np.sum(txt_white[i][j]) == 255:\n",
    "            c_text[i][j] = x\n",
    "\n",
    "cv2.imwrite(\"Output/FinalColouredText.png\", c_text, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Input | Final Coloured Output\n",
    "-|-\n",
    "<img src=\"Images/text.png\"> | <img src=\"Output/FinalColouredText.png\">\n",
    "\n",
    "Now the words in the lines are coloured according to their labeled line. The lines weren't perfect since between the 2nd\n",
    "and 3rd lines there are 2 S and 1 d near each other (vertically) which when the line tresholding wasn't as they are now\n",
    "ended up touching."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}