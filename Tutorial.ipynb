{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Morphology (Tutorial 3)\n",
    "***\n",
    "# Table of Contents\n",
    "1.   [Setup](#Setup)\n",
    "2.   [Exercise 1 - Connected Components](#Exercise-1---Connected-Components)\n",
    "3.   [Exercise 2 - Dilation](#Exercise-2---Dilation)\n",
    "4.   [Exercise 3 - Erosion](#Exercise-3---Erosion)\n",
    "5.   [Exercise 4 - Opening](#Exercise-4---Opening)\n",
    "6.   [Exercise 5 - Closing](#Exercise-5---Closing)\n",
    "7.   [Exercise 6 - Line Segmentation](#Exercise-6---Line-Segmentation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "These libraries are needed for this project:\n",
    "* opencv (cv2) - For image processing\n",
    "* numpy - For its arrays\n",
    "* matplotlib - Plotting histograms\n",
    "* os - File traversal\n",
    "* tqdm.notebook - tqdm progress bars, but for ipynb files\n",
    "* Classes - Custom classes written by me for this assignment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "# Load the images into memory\n",
    "shapes = cv2.imread('Images/shapes.jpg')\n",
    "euro = cv2.imread('Images/Euro_Coins.jpg')\n",
    "text = cv2.imread('Images/text.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1 - Connected Components\n",
    "\n",
    "### getObjects\n",
    "\n",
    "For this exercise I wrote the getObjects function. In the function I first apply a grayscale filter to the input image,\n",
    "followed by a gaussian blur. This blur smoothens the objects edges making it easier to get them labelled.\n",
    "\n",
    "The next step is to get the object labels using the connectedComponents function. Then I colour the components to\n",
    "differentiate between the objects."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def getObjects(image, title):\n",
    "    # gray scale\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # blur using gaussian to help reduce noise\n",
    "    dst = cv2.GaussianBlur(gray,(13,13),cv2.BORDER_DEFAULT)\n",
    "    # treshold image\n",
    "    ret, thresh = cv2.threshold(dst,230,255,cv2.THRESH_BINARY_INV)\n",
    "    # save treshold\n",
    "    cv2.imwrite(\"Output/treshold \"+title+\".png\", thresh, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "    # get labels\n",
    "    ret, labels = cv2.connectedComponents(thresh)\n",
    "\n",
    "    # Colour the labels\n",
    "    label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "    blank_ch = 255 * np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    # save labels as image\n",
    "    cv2.imwrite(\"Output/\"+title+str(ret-1)+\".png\", labeled_img, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "getObjects(shapes.copy(), \"shapes\")\n",
    "getObjects(euro.copy(), \"euro\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs\n",
    "\n",
    "### getROI\n",
    "With getROI I am able to get a ROI of each object in the image. Similar to getObjects, the input image goes through a\n",
    "grayscale, gaussian and threshold filter. Then by using the findContours function I am able to get split the input image\n",
    "into various ROIs by creating a bounding box with each contour's dimensions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def getROI(image, title):\n",
    "    # gray scale\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # blur using gaussian to help reduce noise\n",
    "    dst = cv2.GaussianBlur(gray,(13,13),cv2.BORDER_DEFAULT)\n",
    "    # treshold image\n",
    "    ret, thresh = cv2.threshold(dst,230,255,cv2.THRESH_BINARY_INV)\n",
    "    # getting ROIs with findContours\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    i = 1\n",
    "    for cnt in contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(cnt)\n",
    "        ROI = image[y:y+h,x:x+w]\n",
    "        cv2.imwrite(\"Output/\"+title+\" object \"+str(i)+\".png\", ROI, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "        i+=1\n",
    "\n",
    "getROI(shapes.copy(), \"shapes\")\n",
    "getROI(euro.copy(), \"euro\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2 - Dilation\n",
    "\n",
    "For this exercise I dilate the text.png image using two different kernels too see their results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "%%capture\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "dilate = cv2.dilate(text.copy(), kernel)\n",
    "cv2.imwrite(\"Output/dilated text 3x3.png\", dilate, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "kernel = np.ones((5, 5), 'uint8')\n",
    "dilate = cv2.dilate(text.copy(), kernel)\n",
    "cv2.imwrite(\"Output/dilated text 5x5.png\", dilate, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 3 - Erosion\n",
    "\n",
    "For this exercise I erode the text.png image using two different kernels too see their results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "%%capture\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "erode = cv2.erode(text.copy(), kernel)\n",
    "cv2.imwrite(\"Output/eroded text 3x3.png\", erode, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "kernel = np.ones((5, 5), 'uint8')\n",
    "erode = cv2.erode(text.copy(), kernel)\n",
    "cv2.imwrite(\"Output/eroded text 5x5.png\", erode, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 4 - Opening\n",
    "\n",
    "For this exercise I open the text.png image using two different kernels too see their results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "%%capture\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "open = cv2.morphologyEx(text.copy(), cv2.MORPH_OPEN ,kernel)\n",
    "cv2.imwrite(\"Output/open text 3x3.png\", open, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "kernel = np.ones((5, 5), 'uint8')\n",
    "open = cv2.morphologyEx(text.copy(), cv2.MORPH_OPEN ,kernel)\n",
    "cv2.imwrite(\"Output/open text 5x5.png\", open, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 5 - Closing\n",
    "\n",
    "For this exercise I close the text.png image using two different kernels too see their results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "%%capture\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "close = cv2.morphologyEx(text.copy(), cv2.MORPH_CLOSE ,kernel)\n",
    "cv2.imwrite(\"Output/close text 3x3.png\", close, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "kernel = np.ones((5, 5), 'uint8')\n",
    "close = cv2.morphologyEx(text.copy(), cv2.MORPH_CLOSE ,kernel)\n",
    "cv2.imwrite(\"Output/close text 5x5.png\", close, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 6 - Line Segmentation\n",
    "\n",
    "For this exercise I decided to not use histograms because I felt that for this case, I did not need to use them. Having\n",
    "now learnt the application of the above techniques I recognised that by applying a pseudo close I would be able to\n",
    "extract 4 rectangles that cover the words in the text. I say pseudo since the dilation and erosion applied will have\n",
    "different kernels passed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the grayscale\n",
    "gray = cv2.cvtColor(text.copy(),cv2.COLOR_BGR2GRAY)\n",
    "# Apply the gaussian filter because of the noise\n",
    "dst = cv2.GaussianBlur(gray, (13,13), cv2.BORDER_DEFAULT)\n",
    "# Apply a high threshold\n",
    "ret, thresh = cv2.threshold(dst, 187, 255, cv2.THRESH_BINARY)\n",
    "# Dilate with a wide kernel\n",
    "kernel = np.ones((5, 70), 'uint8')\n",
    "dilate = cv2.morphologyEx(thresh, cv2.MORPH_DILATE ,kernel)\n",
    "# Now apply erosion with a very wide kernel, and as high as it can get before making lines meet\n",
    "kernel = np.ones((25, 130), 'uint8')\n",
    "erode = cv2.morphologyEx(dilate, cv2.MORPH_ERODE ,kernel)\n",
    "# Flip white and black\n",
    "final = cv2.bitwise_not(erode)\n",
    "cv2.imwrite(\"Output/LineThresh.png\", final, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs\n",
    "\n",
    "Now that I have successfully approximated where the lines are, I will use the connectedComponents function and the\n",
    "colouring done previously to create a colour mask of these 4 lines."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get labels\n",
    "ret, labels = cv2.connectedComponents(final)\n",
    "\n",
    "# Colour the labels\n",
    "label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "blank_ch = 255 * np.ones_like(label_hue)\n",
    "labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "labeled_img[label_hue == 0] = 0\n",
    "# save labels as image\n",
    "cv2.imwrite(\"Output/LabelledLines.png\", labeled_img, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs\n",
    "\n",
    "Now that each line is very clearly distinguishable I will use the coloured mask to paint over the text with their new\n",
    "colours.\n",
    "\n",
    "I will achieve this by following these steps:\n",
    "\n",
    "* Apply a 3x3 kernel closure on the image\n",
    "    * This step is done to remove a bunch of noise from the grayed out text image that would otherwise be enhanced by\n",
    "        the next step.\n",
    "* Do the reverse of a gaussian filter and sharpen the image\n",
    "* Erode the image with a 3x3 kernel\n",
    "* Apply a 0 threshold\n",
    "* Flip black and white\n",
    "\n",
    "This will result with a white mask of the letters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = cv2.cvtColor(text.copy(),cv2.COLOR_BGR2GRAY)\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "close = cv2.morphologyEx(gray, cv2.MORPH_CLOSE ,kernel)\n",
    "kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "im = cv2.filter2D(close, -1, kernel)\n",
    "kernel = np.ones((3, 3), 'uint8')\n",
    "erode = cv2.morphologyEx(im, cv2.MORPH_ERODE ,kernel)\n",
    "ret, thresh = cv2.threshold(erode, 0, 255, cv2.THRESH_BINARY)\n",
    "txt_white = cv2.bitwise_not(thresh)\n",
    "cv2.imwrite(\"Output/TextLettersMask.png\", txt_white, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs\n",
    "\n",
    "Now the only thing that is left is to go over the labeled image (the one with the coloured lines). In the loop I use the\n",
    "enumerate function which allows me to check the txt_white image (the one shown above). When the checked pixel is changed\n",
    "to that of the labelled image. This results in the text getting a bit bold and getting some new colour, where the above\n",
    "code identified a line."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_text = text.copy()\n",
    "for i, y in enumerate(labeled_img):\n",
    "    for j, x in enumerate(y):\n",
    "        if np.sum(txt_white[i][j]) == 255:\n",
    "            c_text[i][j] = x\n",
    "\n",
    "cv2.imwrite(\"Output/FinalColouredText.png\", c_text, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "imgs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}